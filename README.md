402.74 million terabytes, that's how much data the world creates everyday. In today's world of big data, storing, organizing and analyzing that data is becoming more important than ever. Data Engineers build the engine that help companies make sense it all.

In this program, I learnt and mastered how to
- Design data models
- Build data warehouses and data lakes
- Automate data pipelines and work with massive datasets
- Create database in Apache Cassandra
- Implement a data warehouse on AWS based on Redshift architecture
- Utilized Spark to work with massive datasets
- And used Apache airflow to schedule, automate and monitor data pipelines

![image](https://github.com/user-attachments/assets/15f98a38-74f5-430e-8dc8-05989f005115)


![image](https://github.com/user-attachments/assets/affcd527-a0e7-4b06-9632-e00cbc8420db)
